{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿'խանգարի', 'բանկեր', 'ճարտարապետների', 'ընկերներից', 'իրականացրել', 'մտածողություն', 'պեկ', 'կոնֆետներ', 'գործողության', 'չինաստանի', 'հսկողական', 'կիրառությանը', 'էլեկտրիկ', 'ունեցողը', 'ազատական', 'հազար', 'համարնախագահի', 'արձանագրեմ', 'լրջությամբ', 'խոստովանել', 'քրդական', 'փուչիկ', 'բալյանին', 'ձգտել', 'խթանիչ', 'պահանջարկված', 'լարումից', 'խորհրդրանի', 'երկերեսանիության', 'արդյունքում', 'semaforo', 'ավիաընկերություններ', 'սկզբնաղբյուրկայքում', 'չինացի', 'որոշեցել', 'ներկայացվելու', 'հուշար', 'ռեմփելի', 'վտակներ', 'հայրենակիցներին', 'օռլովսկայա', 'տարածվում', 'թեյլորին', 'թրեյդինգի', 'բանկնառաջարկումէվարկերիվերակառուցման', 'հետազոտություններն', 'կրկնապատիկ', 'trading', 'քննական', 'հպտհ', 'հարավում', 'շահութահարկ', 'ամուսնու', 'նախագծմանը', 'գեորգի', 'վկայությունը', 'ֆունկցիոնալ', 'թալանչիների', 'ոտքերի', 'մեղավորության', 'աշխուժացում', 'ոլորտն', 'ավելացրած', 'գալոյանն', 'լավագույններից', 'վաշինգտոնըպատժամիջոցներ', 'նեջմեթթին'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "content=open('big.txt', encoding=\"UTF-8\").read()\n",
    "\n",
    "print(content)\n",
    "\n",
    "WORDS = Counter(words(content))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'աբգդեզիլխծկհձզճմյնշոչպջռսվտրցուփքևօֆ'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def edits3(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e3 for e1 in edits1(word) for e2 in edits2(word) for e3 in edits2(e2))\n",
    "def check(text):\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    words=tokenizer.tokenize(text)\n",
    "    alpha_lst=[word.lower () for word in words if word.isalpha()]\n",
    "    ls_txt=set(alpha_lst)\n",
    "    print(ls_txt)\n",
    "    for i in ls_txt:\n",
    "            text=text.replace(str(i),correction(i) )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ողորտն'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ոլորտն'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check('ողորտն')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
